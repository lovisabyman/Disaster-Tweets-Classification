{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-BERT_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karengarm/NLP_Disaster_Tweets_Classification/blob/main/03_BERT_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of Tweets During Crisis-Events using the BERT model\n",
        "\n",
        "This notebook uses the BERT model to classify tweets as informative of non-informative. For a more detailed description of the problem, the data set, the preprocessing steps and for a basline approach, please see the \"Automatic detection of crisis-related messages - NLP.ipynb\" notebook."
      ],
      "metadata": {
        "id": "X7pJkjtpicL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0zR9eh2iZbL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My\\ Drive/CS230"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n",
        "!pip install langdetect\n",
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "lfvog3dTigKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "from google_trans_new_local import google_translator\n",
        "from langdetect import detect\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_curve, auc\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(2)"
      ],
      "metadata": {
        "id": "jSaNBB1dihme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 1\n",
        "How well can a model trained on one type of disaster (i.e floods, shootings, etc.) perform on similar events of the same type?"
      ],
      "metadata": {
        "id": "ValmhAVZikad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(category):\n",
        "  df_train = pd.read_csv('train_data.csv', header = 0, sep = 't')\n",
        "  df_train = df_train.dropna(subset=['tweettext_proc'])\n",
        "  df_test = pd.read_csv('test_data.csv', header = 0, sep = 't')\n",
        "  df_test = df_test.dropna(subset=['tweettext_proc'])\n",
        "\n",
        "  labels_dict = {'Not informative': 0, 'Related and informative':1}\n",
        "  df_train['labels'] = df_train.cat_informativeness.replace(labels_dict)\n",
        "  df_test['labels'] = df_test.cat_informativeness.replace(labels_dict)\n",
        "\n",
        "  train = df_train.loc[df_train['categorization_type'] == category]\n",
        "  test = df_test.loc[df_test['categorization_type'] == category]\n",
        "\n",
        "  X_train = train['tweettext_proc']\n",
        "  y_train = tf.keras.utils.to_categorical(train['labels'], num_classes=2)\n",
        "\n",
        "  X_test = test['tweettext_proc']\n",
        "  y_test = tf.keras.utils.to_categorical(test['labels'], num_classes=2)\n",
        "\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "23HDuSKwijXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the model\n",
        "The BERT model consist of a pre-trained BERT endocing layer, a drop-out layer for regularization and a dense layer using a sigmoid activation function. The model was partly based on [this model](https://www.kaggle.com/code/sanketsonu/bert-model-nlp-with-disaster-tweets) posted on kaggle by Sanket Sonu.\n",
        "\n",
        "The optimizer used is the Adam optimizer, which is used together with the binary crossentropy loss since it is a binary classification problem."
      ],
      "metadata": {
        "id": "HjXftnexioji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bert(learning_rate=1e-3, dropout=0.1):\n",
        "    # Input layer\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='Text')\n",
        "\n",
        "    # Bert encoding\n",
        "    bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\", name = \"Bert_preprocessing\")\n",
        "    bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-24_H-1024_A-16/4\", name = \"Bert_encoding\")\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "    # Classification layer with dropout for regularization\n",
        "    l = tf.keras.layers.Dropout(dropout, name='Dropout')(outputs['pooled_output'])\n",
        "    l = tf.keras.layers.Dense(2, activation='sigmoid', name='Classifier')(l)\n",
        "\n",
        "    # Compile model\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs=[l])\n",
        "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=tf.keras.metrics.CategoricalAccuracy(name='accuracy'))\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ofOCVg9piqLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "Evaluating the model using accuracy, precision, recall, f1-score and mauc."
      ],
      "metadata": {
        "id": "pyOcQqzyitvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_test, y_pred, trhold):\n",
        "    \"\"\"\n",
        "    Evaluation function. For each of the text in evaluation data, it reads the score from\n",
        "    the predictions made. And based on this, it calculates the values of\n",
        "    True positive, True negative, False positive, and False negative.\n",
        "\n",
        "    :param y_test: true labels\n",
        "    :param y_pred: predicted labels\n",
        "    :return: evaluation metrics for classification: accuracy, precision, recall, f1_score and mauc\n",
        "    \"\"\"\n",
        "    # calculating mauc\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
        "    mauc = auc(fpr, tpr)\n",
        "\n",
        "    y_pred  = np.where(y_pred > trhold, 1, 0) \n",
        "    labels = ['Not informative', 'Informative']\n",
        "\n",
        "    # calculating accuracy_score, precision_score, recall_score, f1_score\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1score = f1_score(y_test, y_pred)\n",
        "    \n",
        "    \n",
        "    report = classification_report(y_test, y_pred, target_names = labels)\n",
        "    print(report)\n",
        "    print('mauc: ', mauc)\n",
        "    return accuracy, precision, recall, f1score, mauc "
      ],
      "metadata": {
        "id": "1v_2g82v58rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the model\n",
        "In scenario 1 the model is trained using data from one of three categories and tested on data from the same category."
      ],
      "metadata": {
        "id": "T4xw-UE3i1KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_scenario1(learning_rate=1e-3, dropout=0.1, epochs=5, batch_size=16):  \n",
        "  for cat in ['Earthquake', 'Floods', 'Derailment']:\n",
        "\n",
        "      # Get data\n",
        "      X_train, y_train, X_test, y_test = get_data(cat)\n",
        "\n",
        "      #Training\n",
        "      bert_model = create_bert(learning_rate, dropout)\n",
        "      hist = bert_model.fit(x=X_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_split=.15)\n",
        "\n",
        "      #Testing\n",
        "      y_test_arg = np.argmax(y_test, axis=1)\n",
        "      y_pred = np.argmax(bert_model.predict(X_test),axis=1)\n",
        "\n",
        "      print(cat)\n",
        "      accuracy, precision, recall, f1score, mauc = evaluate(y_test_arg, y_pred, 0.5)"
      ],
      "metadata": {
        "id": "qG3frQg_i3d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_scenario1()"
      ],
      "metadata": {
        "id": "ygK184VprL0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd3c3e5-d007-464c-99e9-d3172a796544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "184/184 [==============================] - 119s 550ms/step - loss: 0.7092 - accuracy: 0.5744 - val_loss: 0.7184 - val_accuracy: 0.5269\n",
            "Epoch 2/5\n",
            "184/184 [==============================] - 100s 543ms/step - loss: 0.6627 - accuracy: 0.6196 - val_loss: 0.6341 - val_accuracy: 0.6385\n",
            "Epoch 3/5\n",
            "184/184 [==============================] - 100s 544ms/step - loss: 0.6277 - accuracy: 0.6519 - val_loss: 0.6816 - val_accuracy: 0.5673\n",
            "Epoch 4/5\n",
            "184/184 [==============================] - 100s 543ms/step - loss: 0.6143 - accuracy: 0.6730 - val_loss: 0.5995 - val_accuracy: 0.6846\n",
            "Epoch 5/5\n",
            "184/184 [==============================] - 100s 543ms/step - loss: 0.5941 - accuracy: 0.6985 - val_loss: 0.5830 - val_accuracy: 0.7000\n",
            "32/32 [==============================] - 31s 928ms/step\n",
            "Earthquake\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not informative       0.51      0.66      0.58       373\n",
            "    Informative       0.76      0.63      0.69       627\n",
            "\n",
            "       accuracy                           0.64      1000\n",
            "      macro avg       0.64      0.65      0.63      1000\n",
            "   weighted avg       0.67      0.64      0.65      1000\n",
            "\n",
            "mauc:  0.645039359304916\n",
            "Epoch 1/5\n",
            "213/213 [==============================] - 134s 554ms/step - loss: 0.5991 - accuracy: 0.7200 - val_loss: 0.6237 - val_accuracy: 0.6456\n",
            "Epoch 2/5\n",
            "213/213 [==============================] - 116s 546ms/step - loss: 0.5857 - accuracy: 0.7171 - val_loss: 0.6531 - val_accuracy: 0.6273\n",
            "Epoch 3/5\n",
            "213/213 [==============================] - 116s 545ms/step - loss: 0.5686 - accuracy: 0.7303 - val_loss: 0.6160 - val_accuracy: 0.6339\n",
            "Epoch 4/5\n",
            "213/213 [==============================] - 116s 545ms/step - loss: 0.5780 - accuracy: 0.7221 - val_loss: 0.5923 - val_accuracy: 0.6473\n",
            "Epoch 5/5\n",
            "213/213 [==============================] - 116s 545ms/step - loss: 0.5703 - accuracy: 0.7291 - val_loss: 0.5813 - val_accuracy: 0.6822\n",
            "69/69 [==============================] - 66s 951ms/step\n",
            "Floods\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not informative       0.68      0.47      0.56       841\n",
            "    Informative       0.73      0.86      0.79      1359\n",
            "\n",
            "       accuracy                           0.71      2200\n",
            "      macro avg       0.70      0.67      0.67      2200\n",
            "   weighted avg       0.71      0.71      0.70      2200\n",
            "\n",
            "mauc:  0.6679637839601932\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 76s 565ms/step - loss: 0.6506 - accuracy: 0.6729 - val_loss: 0.3650 - val_accuracy: 0.9668\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 58s 541ms/step - loss: 0.6176 - accuracy: 0.6806 - val_loss: 0.3027 - val_accuracy: 0.9701\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 58s 545ms/step - loss: 0.5973 - accuracy: 0.6982 - val_loss: 0.5042 - val_accuracy: 0.8472\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 58s 545ms/step - loss: 0.5910 - accuracy: 0.7006 - val_loss: 0.1856 - val_accuracy: 0.9734\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 58s 544ms/step - loss: 0.5774 - accuracy: 0.7159 - val_loss: 0.2679 - val_accuracy: 0.9601\n",
            "32/32 [==============================] - 33s 1s/step\n",
            "Derailment\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not informative       0.68      0.08      0.15       271\n",
            "    Informative       0.74      0.98      0.85       729\n",
            "\n",
            "       accuracy                           0.74      1000\n",
            "      macro avg       0.71      0.53      0.50      1000\n",
            "   weighted avg       0.73      0.74      0.66      1000\n",
            "\n",
            "mauc:  0.5348908427355878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning for scenario 1\n",
        "\n",
        "The best hyperparameters are found by randomly choosing a combination of values for the following hyperparameters:\n",
        "\n",
        "* Learning Rate using log scale\n",
        "* Number of epochs\n",
        "* Batch size\n",
        "* Dropout"
      ],
      "metadata": {
        "id": "SUkgglINm_Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(2)\n",
        "param_dist = {    'dropout': [0.1, 0.3],\n",
        "                  'learning_rate': loguniform.rvs(1e-5, 1e-2, size= 10),\n",
        "                  'epochs': [2, 5, 10, 25],\n",
        "                  'batch_size': [16, 32, 64, 128]\n",
        "                  }\n",
        "dict_parameters = ParameterSampler(param_distributions=param_dist, n_iter=10, random_state=rng)"
      ],
      "metadata": {
        "id": "Hlc9ED12nDhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parameters in dict_parameters:\n",
        "    print(\"===============Now testing the following parameters===============\")\n",
        "    print(\"Learning rate: \", parameters['learning_rate'])\n",
        "    print(\"Dropout: \", parameters['dropout'])\n",
        "    print(\"Epochs: \", parameters['epochs'])\n",
        "    print(\"Batch size: \", parameters['batch_size'])\n",
        "    print()\n",
        "\n",
        "    run_scenario1(learning_rate=parameters['learning_rate'], dropout=parameters['dropout'], epochs=parameters['epochs'], batch_size=parameters['batch_size'])\n"
      ],
      "metadata": {
        "id": "A_c1w0o6tolW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd1f045-e1e2-44a2-b828-4de63da61c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============Now testing the following parameters===============\n",
            "Learning rate:  5.659770986133262e-05\n",
            "Dropout:  0.1\n",
            "Epochs:  25\n",
            "Batch size:  16\n",
            "Epoch 1/25\n",
            "184/184 [==============================] - 118s 547ms/step - loss: 0.7216 - accuracy: 0.5496 - val_loss: 0.7215 - val_accuracy: 0.4577\n",
            "Epoch 2/25\n",
            "184/184 [==============================] - 102s 553ms/step - loss: 0.6935 - accuracy: 0.5795 - val_loss: 0.6820 - val_accuracy: 0.5596\n",
            "Epoch 3/25\n",
            "184/184 [==============================] - 107s 583ms/step - loss: 0.6870 - accuracy: 0.5795 - val_loss: 0.6934 - val_accuracy: 0.5288\n",
            "Epoch 4/25\n",
            " 55/184 [=======>......................] - ETA: 1:00 - loss: 0.6946 - accuracy: 0.5864"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 2\n",
        "\n",
        "How well can a model trained on many type of disaster (i.e floods, shootings, etc.) perform on one disaster type?"
      ],
      "metadata": {
        "id": "oPrE11Squfhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data():\n",
        "  df_train = pd.read_csv('train_data.csv', header = 0, sep = 't')\n",
        "  df_train = df_train.dropna(subset=['tweettext_proc'])\n",
        "\n",
        "  labels_dict = {'Not informative': 0, 'Related and informative':1}\n",
        "  df_train['labels'] = df_train.cat_informativeness.replace(labels_dict)\n",
        "\n",
        "  X_train = df_train['tweettext_proc']\n",
        "  y_train = tf.keras.utils.to_categorical(df_train['labels'], num_classes=2)\n",
        "\n",
        "  return X_train, y_train"
      ],
      "metadata": {
        "id": "8iacheOeux4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(category):\n",
        "  df_test = pd.read_csv('test_data.csv', header = 0, sep = 't')\n",
        "  df_test = df_test.dropna(subset=['tweettext_proc'])\n",
        "\n",
        "  labels_dict = {'Not informative': 0, 'Related and informative':1}\n",
        "  df_test['labels'] = df_test.cat_informativeness.replace(labels_dict)\n",
        "\n",
        "  test = df_test.loc[df_test['categorization_type'] == category]\n",
        "\n",
        "  X_test = test['tweettext_proc']\n",
        "  y_test = tf.keras.utils.to_categorical(test['labels'], num_classes=2)\n",
        "\n",
        "  return X_test, y_test"
      ],
      "metadata": {
        "id": "h9BD-P9VvqGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the model\n",
        "In scenario 2 the model is trained using data from all categories and tested on data for three different categories separately. The same create_model() and evaluate() function as in scenario 1 are used."
      ],
      "metadata": {
        "id": "Nf6TcNFewifV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_scenario2(learning_rate=1e-3, dropout=0.1, epochs=5, batch_size=16): \n",
        "\n",
        "  # Get training data\n",
        "  X_train, y_train = get_train_data()\n",
        "\n",
        "  # Training\n",
        "  bert_model = create_bert(learning_rate, dropout)\n",
        "  hist = bert_model.fit(x=X_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_split=.15)\n",
        "\n",
        "  for cat in ['Earthquake', 'Floods', 'Derailment']:\n",
        "\n",
        "      # Get test data\n",
        "      X_test, y_test = get_test_data(cat)\n",
        "\n",
        "      #Testing\n",
        "      y_test_arg = np.argmax(y_test, axis=1)\n",
        "      y_pred = np.argmax(bert_model.predict(X_test),axis=1)\n",
        "\n",
        "      print(cat)\n",
        "      accuracy, precision, recall, f1score, mauc = evaluate(y_test_arg, y_pred, 0.5)"
      ],
      "metadata": {
        "id": "Kph1Jn6ptPU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_scenario2()"
      ],
      "metadata": {
        "id": "zC5F5VyPvoV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e3e0b1-2e9c-4cd4-8c82-fd30512d41a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1185/1185 [==============================] - 704s 580ms/step - loss: 0.6520 - accuracy: 0.6362 - val_loss: 0.6487 - val_accuracy: 0.5972\n",
            "Epoch 2/5\n",
            "1185/1185 [==============================] - 688s 581ms/step - loss: 0.6039 - accuracy: 0.6789 - val_loss: 0.5921 - val_accuracy: 0.6890\n",
            "Epoch 3/5\n",
            "1185/1185 [==============================] - 642s 542ms/step - loss: 0.5780 - accuracy: 0.6952 - val_loss: 0.5942 - val_accuracy: 0.6678\n",
            "Epoch 4/5\n",
            "1185/1185 [==============================] - 688s 581ms/step - loss: 0.5671 - accuracy: 0.7061 - val_loss: 0.6723 - val_accuracy: 0.6103\n",
            "Epoch 5/5\n",
            "1185/1185 [==============================] - 688s 581ms/step - loss: 0.5560 - accuracy: 0.7161 - val_loss: 0.5719 - val_accuracy: 0.7195\n",
            "32/32 [==============================] - 31s 940ms/step\n",
            "Earthquake\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not informative       0.64      0.78      0.70       373\n",
            "    Informative       0.85      0.74      0.79       627\n",
            "\n",
            "       accuracy                           0.75      1000\n",
            "      macro avg       0.74      0.76      0.75      1000\n",
            "   weighted avg       0.77      0.75      0.76      1000\n",
            "\n",
            "mauc:  0.7579584471781453\n",
            "69/69 [==============================] - 65s 947ms/step\n",
            "Floods\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not informative       0.66      0.75      0.70       841\n",
            "    Informative       0.83      0.76      0.79      1359\n",
            "\n",
            "       accuracy                           0.76      2200\n",
            "      macro avg       0.74      0.75      0.75      2200\n",
            "   weighted avg       0.76      0.76      0.76      2200\n",
            "\n",
            "mauc:  0.7540184387520026\n",
            "32/32 [==============================] - 29s 939ms/step\n",
            "Derailment\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not informative       0.59      0.44      0.51       271\n",
            "    Informative       0.81      0.89      0.85       729\n",
            "\n",
            "       accuracy                           0.77      1000\n",
            "      macro avg       0.70      0.66      0.68      1000\n",
            "   weighted avg       0.75      0.77      0.75      1000\n",
            "\n",
            "mauc:  0.6644749163541018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning for scenario 2\n",
        "The best hyperparameters are found by randomly choosing a combination of values for the following hyperparameters:\n",
        "\n",
        "* Learning Rate using log scale\n",
        "* Number of epochs\n",
        "* Batch size\n",
        "* Dropout"
      ],
      "metadata": {
        "id": "Ur5WztEqwv4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(4)\n",
        "param_dist = {    'dropout': [0.1, 0.3],\n",
        "                  'learning_rate': loguniform.rvs(1e-5, 1e-2, size= 10),\n",
        "                  'epochs': [2, 5, 10, 25],\n",
        "                  'batch_size': [16, 32, 64, 128]\n",
        "                  }\n",
        "dict_parameters = ParameterSampler(param_distributions=param_dist, n_iter=10, random_state=rng)"
      ],
      "metadata": {
        "id": "0Y7r3Ojtwvh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parameters in dict_parameters:\n",
        "    print(\"===============Now testing the following parameters===============\")\n",
        "    print(\"Learning rate: \", parameters['learning_rate'])\n",
        "    print(\"Dropout: \", parameters['dropout'])\n",
        "    print(\"Epochs: \", parameters['epochs'])\n",
        "    print(\"Batch size: \", parameters['batch_size'])\n",
        "    print()\n",
        "\n",
        "    run_scenario2(learning_rate=parameters['learning_rate'], dropout=parameters['dropout'], epochs=parameters['epochs'], batch_size=parameters['batch_size'])"
      ],
      "metadata": {
        "id": "RpR_GZP1xBtz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}