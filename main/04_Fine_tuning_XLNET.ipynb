{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karengarm/NLP_Disaster_Tweets_Classification/blob/main/04_Fine_tuning_XLNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning XLNET"
      ],
      "metadata": {
        "id": "YBbOZXXBAMjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One method which aims to\n",
        "overcome the limitations of the BERT model is XLNet. It does so by combining the bidirectional approach which BERT also utilizes with an autoregressive training which allows for training without\n",
        "masking any words, and thus avoid to remove the context the masked words provides.\n",
        "\n",
        "In this jupyter notebook we will now fine tune XLNet transformers models to track our experiment we will use MLflow Tracking. The XLNET-based model is composed of the XLNet main block and a classification layer. The model used a binary cross entropy as optimization criterion."
      ],
      "metadata": {
        "id": "yETXu-xF_tmm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE6eZv9nH5dS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install sentencepiece\n",
        "!pip install transformers \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from transformers import TFXLNetModel, XLNetTokenizer\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "import json\n",
        "import csv \n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dir_path = '/content/drive/MyDrive/'\n",
        "os.chdir(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n",
        "!databricks configure --host https://community.cloud.databricks.com/\n",
        "import mlflow\n",
        "import mlflow.keras"
      ],
      "metadata": {
        "id": "kaDeOGIeNbJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_test, y_pred, mlflow):\n",
        "    \"\"\"\n",
        "    Evaluation function. For each of the text in evaluation data, it reads the score from\n",
        "    the predictions made. And based on this, it calculates the values of\n",
        "    True positive, True negative, False positive, and False negative.\n",
        "\n",
        "    :param y_test: true labels\n",
        "    :param y_pred: predicted labels\n",
        "    :param labels: list of possible labels\n",
        "    :return: evaluation metrics for classification like, precision, recall, and f_score\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
        "    mauc = auc(fpr, tpr)\n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "    best_trhold =thresholds[ix]\n",
        "\n",
        "    y_pred  = np.where(y_pred > 0.5, 1, 0) \n",
        "    labels = ['Not informative', 'Related and informative']\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "    df_cm = pd.DataFrame(confusion, index=[i for i in labels],\n",
        "                         columns=[i for i in labels])\n",
        "    '''\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sn.heatmap(df_cm, annot=True)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel(\"Predicted label\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    mlflow.log_figure(fig, \"confusion.png\") \n",
        "    '''\n",
        "\n",
        "    # importing accuracy_score, precision_score, recall_score, f1_score\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average= None)\n",
        "    recall = recall_score(y_test, y_pred, average= None)\n",
        "    f1score = f1_score(y_test, y_pred, average= None)\n",
        "    \n",
        "    \n",
        "    report = classification_report(y_test, y_pred, target_names = labels)\n",
        "    print(report)\n",
        "\n",
        "    mlflow.log_metric(\"auc_test\", mauc) \n",
        "    mlflow.log_metric(\"accuracy_test\", accuracy)\n",
        "    mlflow.log_metric(\"precision_NI\", precision[0])  \n",
        "    mlflow.log_metric(\"precision_I\", precision[1])    \n",
        "    mlflow.log_metric(\"recall_NI\", recall[0])\n",
        "    mlflow.log_metric(\"recall_I\", recall[1])\n",
        "    mlflow.log_metric(\"f1score_NI\", f1score[0]) \n",
        "    mlflow.log_metric(\"f1score_I\", f1score[1]) \n",
        "    return accuracy, precision, recall, f1score, mauc \n",
        "\n",
        "def mlflow_log_parameters(cat, parameter):\n",
        "  # Log parameters\n",
        "  mlflow.log_param(\"crisis_type\", cat)\n",
        "  mlflow.log_param(\"dropout\", parameter['dropout'])\n",
        "  mlflow.log_param(\"learning_rate\", parameter['learning_rate'])\n",
        "  mlflow.log_param(\"epochs\", parameter['epochs'])\n",
        "  mlflow.log_param(\"batch_size\", parameter['batch_size'])\n",
        "\n",
        "\n",
        "def get_inputs(tweets, tokenizer, max_len=120):\n",
        "    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n",
        "    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in tweets]\n",
        "    inp_tok = np.array([a['input_ids'] for a in inps])\n",
        "    ids = np.array([a['attention_mask'] for a in inps])\n",
        "    segments = np.array([a['token_type_ids'] for a in inps])\n",
        "    return inp_tok, ids, segments\n",
        "\n",
        "def create_xlnet(mname, ndropout, nlr):\n",
        "    \"\"\" XLNet is composed of a main block and a classification layer with dropout\n",
        "    \"\"\"\n",
        "    # Define token ids as inputs\n",
        "    word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32')\n",
        "\n",
        "    # XLNet model\n",
        "    xlnet = TFXLNetModel.from_pretrained(mname)\n",
        "    xlnet_encodings = xlnet(word_inputs)[0]\n",
        "\n",
        "    # Classification layer with dropout for regularization\n",
        "    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n",
        "    doc_encoding = tf.keras.layers.Dropout(ndropout)(doc_encoding)\n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n",
        "\n",
        "    # Compile model\n",
        "    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=nlr), loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(), 'accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def training_test_mae( mlflow, history):\n",
        "  # Plot training and test loss at each epoch \n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(history.history['accuracy'], label='Training acc')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  mlflow.log_figure(fig, \"training_validation_accuracy.png\") \n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  mlflow.log_figure(fig, \"training_validation_loss.png\") \n",
        "\n",
        "def training_Xlnet(inp_tok, xlnet_model, ndropout, nlr, nepochs, nbatch_size, mlflow):\n",
        "  xlnet = create_xlnet(xlnet_model, ndropout, nlr)\n",
        "  mlflow.keras.log_model(xlnet, \"Xlnet\")\n",
        "  history = xlnet.fit(x=inp_tok, y=y_train, epochs=nepochs, batch_size=nbatch_size, validation_split=.15)\n",
        "  training_test_mae( mlflow, history)\n",
        "  return xlnet"
      ],
      "metadata": {
        "id": "Lwvo1-cqHPAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 1\n"
      ],
      "metadata": {
        "id": "xot3KKZVBIf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first scenario, the goal is to test the effectiveness of the models by only training on data from\n",
        "the same type of disaster. More specifically, each model will be trained and validated\n",
        "on a specific disaster type and then tested on another crisis of the same type. "
      ],
      "metadata": {
        "id": "V2rLdGTlCEL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/karengar@stanford.edu/Xlnet_Scenario1\")"
      ],
      "metadata": {
        "id": "3l_rAEiqN9B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test_data.csv', header = 0, sep = 't')\n",
        "df_train= pd.read_csv('train_data.csv', header = 0, sep = 't')\n",
        "\n",
        "xlnet_model = 'xlnet-base-cased'\n",
        "xlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)  \n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "param_dist = {    'dropout': [0.1,0.2, 0.3],\n",
        "                  'learning_rate': loguniform.rvs(1e-6, 1e-4, size= 10),\n",
        "                  'epochs': [5, 7],\n",
        "                  'batch_size': [16, 32, 64]\n",
        "                  }\n",
        "            \n",
        "dict_parameters = ParameterSampler(param_distributions=param_dist, n_iter= 10, random_state=rng)"
      ],
      "metadata": {
        "id": "STAaPzhjgNiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmMgPw0PIRVX"
      },
      "outputs": [],
      "source": [
        "for parameter in dict_parameters:\n",
        "  print(parameter)\n",
        "  for cat in list(df_test.categorization_type.unique())[1:3]:\n",
        "    with mlflow.start_run(): \n",
        "      mlflow_log_parameters(cat, parameter)\n",
        "      tmp = df_train[df_train['categorization_type'] == cat]\n",
        "      X_train = tmp['tweettext_proc'].values\n",
        "      y_train = np.where(tmp.cat_informativeness =='Related and informative', 1, 0)\n",
        "      tmp = df_test[df_test['categorization_type'] == cat]\n",
        "      X_test = tmp['tweettext_proc'].values \n",
        "      y_test = np.where(tmp.cat_informativeness =='Related and informative', 1, 0)\n",
        "\n",
        "      #Training\n",
        "      inp_tok, ids, segments = get_inputs(X_train, xlnet_tokenizer)\n",
        "      \n",
        "      xlnet = training_Xlnet(inp_tok, xlnet_model, parameter['dropout'], parameter['learning_rate'], parameter['epochs'], parameter['batch_size'], mlflow)\n",
        "\n",
        "      #Testing\n",
        "      inp_tok, ids, segments = get_inputs(X_test, xlnet_tokenizer)\n",
        "      y_pred = xlnet.predict(inp_tok, verbose=True)\n",
        "      print(cat)\n",
        "      accuracy, precision, recall, f1score, mauc = evaluate(y_test, y_pred, mlflow)\n",
        "      mlflow.end_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 2"
      ],
      "metadata": {
        "id": "9Q3YZ8cNBaPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second scenario aims to test the performance of the models in the transfer of information between disasters. In this case the models were trained using 22 293 tweets belonging to 22 different disasters and tested on the remaining 4 disasters. The same test sets as scenario 1 was used, but the training set was not divided into different crisis types. Instead the data was used all together, and also included other crisis types besides derailments, earthquakes and floods. As for scenario 1 the training and validation set was split randomly, with 85\\% in the training set and 15\\% in the validation set.\n"
      ],
      "metadata": {
        "id": "QV5kOlkLCK2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/karengar@stanford.edu/Xlnet_Scenario2\")"
      ],
      "metadata": {
        "id": "_l_abLRVBD6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test_data.csv', header = 0, sep = 't')\n",
        "df_train= pd.read_csv('train_data.csv', header = 0, sep = 't')\n",
        "\n",
        "xlnet_model = 'xlnet-base-cased'\n",
        "xlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)  \n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "param_dist = {    'dropout': [0.1, 0.2,  0.3],\n",
        "                  'learning_rate': loguniform.rvs(1e-6, 1e-4, size= 10),\n",
        "                  'epochs': [5, 7],\n",
        "                  'batch_size': [16, 32]\n",
        "                  }\n",
        "dict_parameters = ParameterSampler(param_distributions=param_dist, n_iter=1, random_state=rng)\n",
        "\n",
        "X_train = df_train['tweettext_proc'].values\n",
        "y_train = np.where(df_train.cat_informativeness =='Related and informative', 1, 0)\n",
        "\n",
        "for parameter in dict_parameters:\n",
        "  print(list(parameter))\n",
        "  #Training\n",
        "  inp_tok, ids, segments = get_inputs(X_train, xlnet_tokenizer)\n",
        "  xlnet = training_Xlnet(inp_tok, xlnet_model, parameter['dropout'], parameter['learning_rate'], parameter['epochs'], parameter['batch_size'], mlflow)\n",
        "  for cat in df_test.categorization_type.unique():\n",
        "    with mlflow.start_run(): \n",
        "      mlflow_log_parameters(cat, parameter) \n",
        "      drive.mount('/content/drive')\n",
        "      tmp = df_test[df_test['categorization_type'] == cat]\n",
        "      X_test = tmp['tweettext_proc'].values \n",
        "      y_test = np.where(tmp.cat_informativeness =='Related and informative', 1, 0)\n",
        "\n",
        "      #Testing\n",
        "      inp_tok, ids, segments = get_inputs(X_test, xlnet_tokenizer)\n",
        "      y_pred = xlnet.predict(inp_tok, verbose=True)\n",
        "      print(cat)\n",
        "      accuracy, precision, recall, f1score, mauc = evaluate(y_test, y_pred, mlflow)\n",
        "      mlflow.end_run()\n",
        "    "
      ],
      "metadata": {
        "id": "e7cI-JYqBh7M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "04_Fine_tuning_XLNET.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}