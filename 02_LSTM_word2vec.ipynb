{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karengarm/NLP_Disaster_Tweets_Classification/blob/main/02_LSTM_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "dir_path = '/content/drive/MyDrive/'\n",
        "os.chdir(dir_path)\n",
        "\n",
        "def evaluate(y_test, y_pred, mlflow):\n",
        "    \"\"\"\n",
        "    Evaluation function. For each of the text in evaluation data, it reads the score from\n",
        "    the predictions made. And based on this, it calculates the values of\n",
        "    True positive, True negative, False positive, and False negative.\n",
        "\n",
        "    :param y_test: true labels\n",
        "    :param y_pred: predicted labels\n",
        "    :param labels: list of possible labels\n",
        "    :return: evaluation metrics for classification like, precision, recall, and f_score\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
        "    mauc = auc(fpr, tpr)\n",
        "    # calculate the g-mean for each threshold\n",
        "    gmeans = np.sqrt(tpr * (1-fpr))\n",
        "    # locate the index of the largest g-mean\n",
        "    ix = np.argmax(gmeans)\n",
        "    best_trhold =thresholds[ix]\n",
        "\n",
        "    y_pred  = np.where(y_pred > 0.5, 1, 0) \n",
        "    labels = ['Not informative', 'Related and informative']\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "    df_cm = pd.DataFrame(confusion, index=[i for i in labels],\n",
        "                         columns=[i for i in labels])\n",
        "    '''\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sn.heatmap(df_cm, annot=True)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel(\"Predicted label\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    mlflow.log_figure(fig, \"confusion.png\") \n",
        "    '''\n",
        "\n",
        "    # importing accuracy_score, precision_score, recall_score, f1_score\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average= None)\n",
        "    recall = recall_score(y_test, y_pred, average= None)\n",
        "    f1score = f1_score(y_test, y_pred, average= None)\n",
        "    \n",
        "    \n",
        "    report = classification_report(y_test, y_pred, target_names = labels)\n",
        "    print(report)\n",
        "\n",
        "    mlflow.log_metric(\"auc_test\", mauc) \n",
        "    mlflow.log_metric(\"accuracy_test\", accuracy)\n",
        "    mlflow.log_metric(\"precision_NI\", precision[0])  \n",
        "    mlflow.log_metric(\"precision_I\", precision[1])    \n",
        "    mlflow.log_metric(\"recall_NI\", recall[0])\n",
        "    mlflow.log_metric(\"recall_I\", recall[1])\n",
        "    mlflow.log_metric(\"f1score_NI\", f1score[0]) \n",
        "    mlflow.log_metric(\"f1score_I\", f1score[1]) \n",
        "    return accuracy, precision, recall, f1score, mauc \n",
        "    \n",
        "def mlflow_log_parameters(cat, parameter):\n",
        "  # Log parameters\n",
        "  mlflow.log_param(\"crisis_type\", cat)\n",
        "  mlflow.log_param(\"dropout\", parameter['dropout'])\n",
        "  mlflow.log_param(\"learning_rate\", parameter['learning_rate'])\n",
        "  mlflow.log_param(\"epochs\", parameter['epochs'])\n",
        "  mlflow.log_param(\"batch_size\", parameter['batch_size'])\n",
        "\n",
        "def get_input(data, vocabulary_size, max_length):\n",
        "  # integer encode the documents\n",
        "\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words= vocabulary_size)\n",
        "  tokenizer.fit_on_texts(data)\n",
        "  sequences = tokenizer.texts_to_sequences(data)\n",
        "  data = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=50)\n",
        "  # pad documents to a max length\n",
        "  padded_docs = tf.keras.preprocessing.sequence.pad_sequences(data , maxlen=max_length, padding='post')\n",
        "  return padded_docs\n",
        "\n",
        "def create_lstm(vocabulary_size, max_length, ndropout, nlr):\n",
        "  \"\"\" LSTM is composed of a main block and a classification layer with dropout\n",
        "  \"\"\"\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(Embedding(vocabulary_size, 50, input_length=max_length))\n",
        "  model.add(tf.keras.layers.SpatialDropout1D(0.3))\n",
        "  model.add(tf.keras.layers.LSTM(256, dropout=ndropout, recurrent_dropout=0.2))\n",
        "  model.add(tf.keras.layers.Dense(256, activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "  # compile the model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=nlr), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "  return model\n",
        "\n",
        "def training_test_mae( mlflow, history):\n",
        "  # Plot training and test loss at each epoch \n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(history.history['accuracy'], label='Training acc')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  mlflow.log_figure(fig, \"training_validation_accuracy.png\") \n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  mlflow.log_figure(fig, \"training_validation_loss.png\")\n"
      ],
      "metadata": {
        "id": "iYH08FFPtOCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n",
        "!databricks configure --host https://community.cloud.databricks.com/\n",
        "import mlflow\n",
        "import mlflow.keras"
      ],
      "metadata": {
        "id": "i-GwC0n4xsrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 1"
      ],
      "metadata": {
        "id": "N4vMuxXe3OYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/karengar@stanford.edu/LSTM_Scenario1_SpatialDropout\")"
      ],
      "metadata": {
        "id": "BhoaygsMxe2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test_data.csv', header = 0, sep = 't')\n",
        "df_train= pd.read_csv('train_data.csv', header = 0, sep = 't')\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "param_dist = {    'dropout': [0.1, 0.2, 0.3],\n",
        "                  'learning_rate': loguniform.rvs(1e-5, 1e-3, size= 10),\n",
        "                  'epochs': [5, 8, 25, 50],\n",
        "                  'batch_size': [64, 128, 450, 512]\n",
        "                  }\n",
        "dict_parameters = ParameterSampler(param_distributions=param_dist, n_iter=10, random_state=rng)\n",
        "vocabulary_size = 20000\n",
        "max_length = 50"
      ],
      "metadata": {
        "id": "GktdhRuLxlh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parameter in dict_parameters:\n",
        "  print(parameter)\n",
        "  for cat in df_test.categorization_type.unique(): \n",
        "    tmp = df_train[df_train['categorization_type'] == cat]\n",
        "    X_train = tmp['tweettext_proc'].values\n",
        "    y_train = np.where(tmp.cat_informativeness =='Related and informative', 1, 0)\n",
        "    tmp = df_test[df_test['categorization_type'] == cat]\n",
        "    X_test = tmp['tweettext_proc'].values \n",
        "    y_test = np.where(tmp.cat_informativeness =='Related and informative', 1, 0)\n",
        "    with mlflow.start_run(): \n",
        "      mlflow_log_parameters(cat, parameter)\n",
        "      padded_docs = get_input(X_train, vocabulary_size, max_length)\n",
        "      # define the model\n",
        "      model = create_lstm(vocabulary_size, max_length, parameter['dropout'], parameter['learning_rate'])\n",
        "      # fit the model\n",
        "      mlflow.keras.log_model(model, \"Lstm\")\n",
        "      history = model.fit(padded_docs, np.array(y_train), epochs= parameter['epochs'], batch_size=parameter['batch_size'], validation_split=.15)\n",
        "      training_test_mae( mlflow, history)\n",
        "      #Testing\n",
        "      padded_docs = get_input(X_test, vocabulary_size, max_length)\n",
        "      y_pred = model.predict(padded_docs, verbose=True)\n",
        "      accuracy, precision, recall, f1score, mauc = evaluate(y_test, y_pred, mlflow)\n",
        "      mlflow.end_run()"
      ],
      "metadata": {
        "id": "CfKrD7m3n1Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario 2"
      ],
      "metadata": {
        "id": "YrzRhWDaAg8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/karengar@stanford.edu/LSTM_Scenario2_SpatialDropout\")"
      ],
      "metadata": {
        "id": "ChySZtN_6SUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test_data.csv', header = 0, sep = 't')\n",
        "df_train= pd.read_csv('train_data.csv', header = 0, sep = 't')\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "param_dist = {    'dropout': [0.1, 0.2, 0.3],\n",
        "                  'learning_rate': loguniform.rvs(1e-5, 1e-3, size= 10),\n",
        "                  'epochs': [5,8, 25],\n",
        "                  'batch_size': [64, 128, 450, 512]\n",
        "                  }\n",
        "dict_parameters = ParameterSampler(param_distributions=param_dist, n_iter=1, random_state=rng)\n",
        "vocabulary_size = 20000\n",
        "max_length = 50\n",
        "\n",
        "X_train = df_train['tweettext_proc'].values\n",
        "y_train = np.where(df_train.cat_informativeness =='Related and informative', 1, 0)\n",
        "padded_docs_train = get_input(X_train, vocabulary_size, max_length)"
      ],
      "metadata": {
        "id": "zbCXtivjAl-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parameter in dict_parameters:\n",
        "  print(parameter)\n",
        "  # define the model\n",
        "  model = create_lstm(vocabulary_size, max_length, parameter['dropout'], parameter['learning_rate'])\n",
        "  history = model.fit(padded_docs_train, np.array(y_train), epochs= parameter['epochs'], batch_size=parameter['batch_size'], validation_split=.15)\n",
        "  training_test_mae( mlflow, history)\n",
        "  for cat in df_test.categorization_type.unique(): \n",
        "      tmp = df_test[df_test['categorization_type'] == cat]\n",
        "      X_test = tmp['tweettext_proc'].values \n",
        "      y_test = np.where(tmp.cat_informativeness =='Related and informative', 1, 0)\n",
        "      # fit the model\n",
        "      with mlflow.start_run(): \n",
        "        mlflow_log_parameters(cat, parameter)\n",
        "        mlflow.keras.log_model(model, \"Lstm\")\n",
        "        #Testing\n",
        "        padded_docs = get_input(X_test, vocabulary_size, max_length)\n",
        "        y_pred = model.predict(padded_docs, verbose=True)\n",
        "        accuracy, precision, recall, f1score, mauc = evaluate(y_test, y_pred, mlflow)\n",
        "        mlflow.end_run()"
      ],
      "metadata": {
        "id": "N-rS894fA4nm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "02_LSTM_word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}